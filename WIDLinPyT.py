#ML is turning data, into numbers and finding patterns in them.
# ML and DL algorithms, Code and mathematical
#Artificial Intelligence >> Machine Learning >> Deep Learning >> myself

#Fudamental of ML:: reproduce meal>>> input >>> rules ( cut vegetables, season ketke, .. >> output)
#ML Input >> output by figureing out the rules. In ML sense Supervise learning (features, labels) >> output by figureing out the rules

#Why ML/DL, cumbersome rules, and not practical.
#Good reason: Why not?
#Better reason: For a complex problem, can you thing of the rules(driving car) rules don't' work?
#ML for anything your can convert into numbers to find patterns. Any input from the uninverse
#Google #rule, if you can use a simple rule-based system so , dong you use ML, just use rule-based

#ML powerful, fun, excited, rule-based system is still good enough
# DL is good for problems for long long list of rules, so tranditional ML/rules-based system do not work
#continually changing environments >>> deep learning can adapt to new scenarios.
#Discovering insights within large collection of data.  101 different kinds of food look like.
# What a banana is looking like >>> what not a banana is not look like a banana.
#When you need explainability- the patterns learned by a deep learning model are typically uniterpretable by a human
#numbers of million
#When the tranditional approach is better opition, use it.
#When error are unaccepatable, output of DL are not always predicatable
#When you don't have much data, deep learning models

#Machine Learning vs Deep learning (ML vs DL)
#structured data: rows an columns >>> dml XGBOOSt >> rather than DL algorithms. art than science
#DL are better for unstructured data like : NLP, image data, unstructured data, audio data
# user a Neural network... Unstructureddata NNN
#Random forest, Gradient boosted mdoel, Naive Bayes, Nearest neighbour, Support vector Machine
#Neural networks, Fully connected NN, CNN, RNN, Transformer
#Part art, part science >>>>
#What are Neural networks: Data (image, NLP, speach) >>> turned to numbers>>> representation
#Inputs >> numbers >> pass(CNN) >>> hidden layers >>> inputs >> numbers >>> output by figureing out the patterns
#image (CNN) , NLP (Transformer) output >> learned representation >>> convert those outputs to
#human readable/understandable terms
#images of food >> represent a tweet to numbers >>> to readable
#Anatomy of Neural networks (NN) : inputs >> hidden layers >> output layer ::: Resnet152
#hidden layers as many as your want>>> output layer learn representation or prediction probablitiy
#overall architecture>> input >> hidden.>>outputs: patterns >>> embedding, weights, feature representation
#feature vector>>>
#Types of Learning: Supervised learning, Unsupervised learning, Transfer Learning, Reinforcement Learning
#Semisupervised learning, one shot learning. data, labels. (only data) learn inherent representation
#it would not necearily knows what is it. (only labels)
#Transfer learning: taking what model has already leaned and then goes to our.
#Reinforcement learning >>> environments >> reward, action, observation
#What is deep Learning actually used for? >>> ML >> anything (data>> numbers)>> part art/science
#if you don't need it, you dont use it.
#Recommendations, DL >>> Speech Recognition, Hey Supervise#Computer Vision >> came off.
#security camer >>> detected when the car hit my car>>> Computer vision >> object detection
#to catch a car>>>
#NLP >>> Not spam >>> spam.... text>>> desciding which good or not.

#Sequence to sequence (seq2seq) Classification classe regression : many pixels from xs, ys. Classification predicting is one more ontherr.


